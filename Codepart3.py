# -*- coding: utf-8 -*-
"""Part3.ipynb

Automatically generated by Colaboratory.

"""

train_dir = os.path.join(base_dir,'train')
val_dir   = os.path.join(base_dir,'val')
test_dir  = os.path.join(base_dir,'test')
if not os.path.exists(train_dir):
  print(train_dir +' does not exist.')
if not os.path.exists(val_dir):
  print(val_dir +' does not exist.')
if not os.path.exists(test_dir):
  print(test_dir +' does not exist.')

n_train_per_class = 1600 
n_val_per_class = 2000
n_test_per_class = 2000

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range = 40,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    shear_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True,
    fill_mode = 'nearest')
test_datagen = ImageDataGenerator(rescale=1./255)

batch_size = 32
# this is a generator that will read pictures found in
# subfolers of training data, and indefinitely generate
# batches of training image data
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (150,150),# all images will be resized to 150x150
    batch_size=batch_size,
    class_mode='binary')# since we use binary_crossentropy loss, we need binary labels

# this is a similar generator, for validation data
val_generator = test_datagen.flow_from_directory(
    val_dir,
    target_size = (150,150),
    batch_size=batch_size,
    class_mode='binary')

import keras
from keras.applications.vgg16 import VGG16 
from PIL import Image

Image.MAX_IMAGE_PIXELS = None


# build the convolutional base of VGG16 network
VGG16_conv_base = VGG16(weights = 'imagenet', # the model if pre-trained on ImageNet
                  include_top = False,
                  input_shape = (150,150,3))

# set the early layers (up to the 'block5_conv1')
# to non-trainable (weights will not be updated)
for layer in VGG16_conv_base.layers[:14]:
    layer.trainable = False

VGG16_conv_base.summary()

sgd = gradient_descent_v2.SGD(lr=1e-4, momentum=0.9)

top_model = Sequential()
top_model.add(VGG16_conv_base)
top_model.add(Flatten())
top_model.add(Dropout(0.5))#
top_model.add(Dense(256, activation='relu'))
top_model.add(Dropout(0.5))
top_model.add(Dense(1, activation='sigmoid'))

top_model.summary()
from keras.utils.vis_utils import plot_model
plot_model(top_model, show_shapes=True)

top_model.compile(loss='binary_crossentropy',
              optimizer= sgd,
              metrics=['accuracy'])

history=top_model.fit(
        train_generator,
        steps_per_epoch=33,
        epochs=25,
        validation_data=val_generator,
        validation_steps= 6)

import matplotlib.pyplot as plt
fig = plt.figure(figsize = [6,3], dpi = 480)
fig.add_subplot(2,1,1)
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.grid(True)
plt.ylim([0,1.0])
plt.xlabel('epoch')

fig.add_subplot(2,1,2)
plt.plot(history.history['accuracy'], label='train accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.legend()
plt.grid(True)
plt.ylim([0,1.0])
plt.xlabel('epoch')

model_folder = '/content/gdrive/My Drive/Colab Notebooks/models'
if not os.path.exists(model_folder):
    os.mkdir(model_folder)
top_model.save(model_folder+'/CNN_vgg(3).h5')

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size = (150, 150),
    batch_size = batch_size,
    class_mode = 'binary'
)
test_loss, test_acc = top_model.evaluate(test_generator, steps=len(n_test_per_class) // batch_size)
print('Test accuracy: ', test_acc)
